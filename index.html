<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <script
      src="https://kit.fontawesome.com/0cae1cf83d.js"
      crossorigin="anonymous"
    ></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap"
      rel="stylesheet"
    />
    <title>A Unified Encoder for Efficient Multi-Task Inference</title>
    <style>
      body {
        font-family: "Lato", sans-serif;
      }
    </style>
  </head>

  <body>
    <div id="header" class="mt-10 w-full max-w-[950px] mx-auto">
      <h2 id="title" class="text-center text-3xl">
        Human Insights Driven Latent Space for Different Driving Perspectives: A
        <b>Unified Encoder</b> for Efficient <b>Multi-Task</b> Inference
      </h2>
      <ul
        id="authors"
        class="mt-10 flex flex-col gap-x-3 justify-center sm:flex-row"
      >
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Huy-Dung Nguyen <sup>1</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Anass Bairouk <sup>1</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Mirjana Maras <sup>1</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Patrick Chareyre <sup>1</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Ramin Hasani <sup>2</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Marc Blanchon <sup>1</sup>
        </li>
        <li
          class="inline-block text-[#1772d0] hover:text-[#f09228] text-center"
        >
          Daniela Rus <sup>2</sup>
        </li>
      </ul>
      <ul class="flex justify-evenly flex-1 mt-2 flex-col sm:flex-row">
        <li class="text-center"><sup>1</sup>Capgemini Engineering</li>
        <li class="text-center"><sup>2</sup>MIT University</li>
      </ul>
      <ul class="flex justify-center flex-1 mt-10 text-white gap-2">
        <li
          class="bg-[#363636] py-1 px-4 rounded-full hover:bg-[#ccc] hover:text-black hover:cursor-pointer text-center max-w-24"
        >
          <i class="fa-solid fa-file-pdf mr-1"></i>Arxiv
        </li>
        <li
          class="bg-[#363636] py-1 px-4 rounded-full hover:bg-[#ccc] hover:text-black hover:cursor-pointer text-center max-w-24"
        >
          <i class="fa-solid fa-file-pdf mr-1"></i>Code
        </li>
      </ul>
    </div>
    <div id="quantitative-results" class="w-full max-w-[1400px] mx-auto mt-20">
      <div
        class="pt-[16.1%] bg-[url('./assets/img/qualitative_results.png')] bg-cover bg-no-repeat"
      ></div>
      <div class="grid grid-cols-7 text-center">
        <div>Input</div>
        <div>Panoptic seg.</div>
        <div>Instance seg.</div>
        <div>Semantic seg.</div>
        <div>Depth</div>
        <div>Motion mask</div>
        <div>Independent Flow</div>
      </div>
    </div>

    <div id="content" class="h-[4000px]">
      <div id="abstract" class="w-full max-w-[950px] mx-auto mt-10">
        <h3 class="text-3xl">Abstract</h3>
        <p class="mt-3 text-justify">
          Autonomous driving is one of the most promising yet challenging areas
          in technology today. A fully autonomous system has the potential to
          revolutionize road traffic by enhancing safety and efficiency through
          the reduction of human errors and congestion. One critical challenge
          in achieving this is accurate steering angle estimation, which
          directly affects a vehicle's ability to navigate and maintain control.
          Recent advances in deep learning have enabled the estimation of
          steering angles directly from raw camera data. However, limited
          navigation data can lead to suboptimal feature learning. To address
          this, we propose a shared encoder trained on multiple computer vision
          tasks critical for urban navigation, such as depth, pose, and 3D scene
          flow estimation, as well as semantic, instance, panoptic, and motion
          segmentation. By incorporating diverse visual information used by
          humans during navigation, this unified encoder may enhance steering
          angle estimation. To achieve effective multi-task learning within a
          single encoder, we introduce a multi-scale feature network for pose
          estimation to improve depth learning. Additionally, we employ
          knowledge distillation from a multi-backbone model pretrained on these
          tasks to stabilize training and boost performance. Our findings
          demonstrate that a shared backbone trained on diverse visual tasks
          significantly improves steering angle estimation, underscoring the
          potential of integrating human-like perception into autonomous driving
          systems.
        </p>
      </div>

      <div id="model" class="w-full max-w-[950px] mx-auto mt-10 flex flex-col">
        <h3 class="text-3xl">Model architecture</h3>
        <div class="flex flex-col">
          <h4 class="text-2xl mt-5">Model overview</h4>
          <img
            class="inline-block w-full max-w-[500px] mx-auto mt-5"
            src="./assets/img/overall_architecture.png"
            alt="overview"
          />
        </div>

        <div class="flex flex-col">
          <h4 class="text-2xl mt-5">Encoder architecture details</h4>
          <img
            class="inline-block w-full max-w-[800px] mx-auto mt-5"
            src="./assets/img/swin_architecture.png"
            alt="swin"
          />
        </div>

        <div class="flex flex-col">
          <h4 class="text-2xl mt-5">Pose decoder architecture details</h4>
          <img
            class="inline-block w-full max-w-[800px] mx-auto mt-5"
            src="./assets/img/pose_decoder.png"
            alt="pose"
          />
        </div>

        <div class="flex flex-col">
          <h4 class="text-2xl mt-5">Depth decoder architecture details</h4>
          <img
            class="inline-block w-full max-w-[800px] mx-auto mt-5"
            src="./assets/img/depth_decoder.png"
            alt="depth"
          />
        </div>
      </div>
    </div>
  </body>
  <script src="https://cdn.tailwindcss.com"></script>
</html>
